# -*- coding: utf-8 -*-
"""stat527 Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eThl282zvaXWcBGD5f0LoRkMIBiZQTQN
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression, LassoCV
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegressionCV
from sklearn.utils import resample
from sklearn.feature_selection import RFE
import os
from sklearn.metrics import log_loss
from itertools import combinations
import pymc as pm
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
import seaborn as sns

from google.colab import drive
from sklearn.metrics import roc_curve, auc
drive.mount('/content/drive')
os.chdir('/content/drive/MyDrive/stat527')

# data intro
data = pd.read_csv('diabetes.csv')
data.info()
data.describe()

plt.figure(figsize=(12, 6))
for i, col in enumerate(data.columns[:-1], 1):
    plt.subplot(2, 4, i)
    sns.histplot(data[col], kde=True, bins=20)
    plt.title(f"Distribution of {col}")
plt.tight_layout()
plt.show()

columns_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
zero_counts = (data[columns_with_zeros] == 0).sum()

zero_ratios = (data[columns_with_zeros] == 0).mean() * 100

print("zero counts：")
print(zero_counts)

print("\nzero ratios：")
print(zero_ratios)

columns_with_zeros_repalcebymedian = ['Glucose', 'BloodPressure',  'BMI']
data[columns_with_zeros_repalcebymedian] = data[columns_with_zeros_repalcebymedian].replace(0, np.nan)

missing_values_summary = data.isnull().mean() * 100
print("missing value ratios：")
print(missing_values_summary)

for column in columns_with_zeros:
    data[column].fillna(data[column].median(), inplace=True)

print(data.describe())

plt.figure(figsize=(12, 6))
for i, col in enumerate(data.columns[:-1], 1):
    plt.subplot(2, 4, i)
    sns.histplot(data[col], kde=True, bins=20)
    plt.title(f"Distribution of {col}")
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 8))
correlation_matrix = data.corr()
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Feature Correlation Matrix")
plt.show()

X = data.drop('Outcome', axis=1)
y = data['Outcome']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

n_features = X_train.shape[1]

traces = []
ppcs = []

for i in range(1, n_features + 1):
    with pm.Model() as model:
        alpha = pm.Normal('alpha', mu=0, sigma=10)
        betas = pm.Normal('betas', mu=0, sigma=10, shape=i)
        sigma = pm.HalfNormal('sigma', sigma=1)
        p = pm.math.sigmoid(alpha + pm.math.dot(X_train[:, :i], betas))

        Y_obs = pm.Bernoulli('Y_obs', p=p, observed=y_train)
        trace = pm.sample(2000, return_inferencedata=False)
        traces.append(trace)
        ppc = pm.sample_posterior_predictive(trace, var_names=['alpha', 'betas'])
        ppcs.append(ppc)

log_likelihoods = []
for i, ppc in enumerate(ppcs, start=1):
    alpha = np.where(ppc.posterior_predictive['alpha'] <= 0, 1e-10, ppc.posterior_predictive['alpha'])

    log_likelihood = np.sum(np.log(alpha))
    log_likelihoods.append(log_likelihood)
    print(f"model {i}'s log likelihood is': {log_likelihood}")

bayes_factors = []

for i in range(len(log_likelihoods) - 1):
    log_diff = log_likelihoods[-1] - log_likelihoods[i]
    bayes_factor = np.exp(log_diff)

    bayes_factors.append((len(log_likelihoods), i + 1, log_diff, bayes_factor))
    print(f"model {len(log_likelihoods)} and model {i + 1} loglikihood difference {log_diff:.2f}，Bayes factor is {bayes_factor:.2f}")

model_3_ll = log_likelihoods[2]
model_7_ll = log_likelihoods[6]
log_diff = model_7_ll - model_3_ll
bayes_factor = np.exp(log_diff)
print(f"model 7 与 model 3 loglikihood differnce is {log_diff:.2f}，Bayes factor is {bayes_factor:.2f}")

model_4_ll = log_likelihoods[3]
log_diff = model_7_ll - model_4_ll
bayes_factor = np.exp(log_diff)
print(f"model 7 与 model 4 loglikihood differnce is {log_diff:.2f}，Bayes factor is {bayes_factor:.2f}")

model_6_ll = log_likelihoods[5]
log_diff = model_7_ll - model_6_ll
bayes_factor = np.exp(log_diff)
print(f"model 7 与 model 6 loglikihood differnce is {log_diff:.2f}，Bayes factor is {bayes_factor:.2f}")

selected_features = range(7)

X_train_selected = X_train[:, selected_features]
X_test_selected = X_test[:, selected_features]

log_reg = LogisticRegression()

log_reg.fit(X_train_selected, y_train)

y_pred_bay = log_reg.predict(X_test_selected)

accuracy = accuracy_score(y_test, y_pred_bay)
print(f"Model accuracy with the first 7 features: {accuracy:.4f}")

lasso = LassoCV(cv=5).fit(X_train, y_train)
lasso_selected_features = np.where(lasso.coef_ != 0)[0]
X_train_lasso = X_train[:, lasso_selected_features]
X_test_lasso = X_test[:, lasso_selected_features]

initial_model = LogisticRegression(max_iter=1000).fit(X_train, y_train)
initial_coef = np.abs(initial_model.coef_).flatten()
weights = 1 / (initial_coef + 1e-5)
adaptive_lasso = LassoCV(cv=5).fit(X_train * weights, y_train)
adaptive_selected_features = np.where(adaptive_lasso.coef_ != 0)[0]
X_train_adaptive_lasso = X_train[:, adaptive_selected_features]
X_test_adaptive_lasso = X_test[:, adaptive_selected_features]

rfe = RFE(estimator=LogisticRegression(max_iter=1000), n_features_to_select=5)
rfe.fit(X_train, y_train)
rfe_selected_features = np.where(rfe.support_)[0]
X_train_rfe = X_train[:, rfe_selected_features]
X_test_rfe = X_test[:, rfe_selected_features]

lasso_log_reg = LogisticRegression(max_iter=1000).fit(X_train_lasso, y_train)
y_pred_lasso = lasso_log_reg.predict(X_test_lasso)

adaptive_lasso_log_reg = LogisticRegression(max_iter=1000).fit(X_train_adaptive_lasso, y_train)
y_pred_adaptive_lasso = adaptive_lasso_log_reg.predict(X_test_adaptive_lasso)

rfe_log_reg = LogisticRegression(max_iter=1000).fit(X_train_rfe, y_train)
y_pred_rfe = rfe_log_reg.predict(X_test_rfe)

def evaluate_model(y_true, y_pred, method_name):
    cm = confusion_matrix(y_true, y_pred)
    report = classification_report(y_true, y_pred, output_dict=True)
    type_i_error = cm[0][1] / (cm[0][1] + cm[0][0])
    type_ii_error = cm[1][0] / (cm[1][0] + cm[1][1])

    print(f"Results for {method_name}:")
    print("Confusion Matrix:")
    print(cm)
    print("Classification Report:")
    print(classification_report(y_true, y_pred))
    print(f"Type I Error (False Positive Rate): {type_i_error}")
    print(f"Type II Error (False Negative Rate): {type_ii_error}")
    print("\n")

evaluate_model(y_test, y_pred_lasso, "LASSO")

evaluate_model(y_test, y_pred_adaptive_lasso, "Adaptive LASSO")

evaluate_model(y_test, y_pred_rfe, "RFE")

evaluate_model(y_test, y_pred_bay, "Bayes")

def plot_all_roc_curves(y_true, y_probs_dict):
    plt.figure()
    for method_name, y_prob in y_probs_dict.items():
        fpr, tpr, _ = roc_curve(y_true, y_prob)
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, lw=2, label=f'{method_name} (AUC = {roc_auc:.2f})')

    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curves for All Models')
    plt.legend(loc='lower right')
    plt.show()

y_prob_lasso = lasso_log_reg.predict_proba(X_test_lasso)[:, 1]
y_prob_adaptive_lasso = adaptive_lasso_log_reg.predict_proba(X_test_adaptive_lasso)[:, 1]
y_prob_rfe = rfe_log_reg.predict_proba(X_test_rfe)[:, 1]
y_prob_bay = log_reg.predict_proba(X_test_selected)[:, 1]

y_probs_dict = {
    "LASSO": y_prob_lasso,
    "Adaptive LASSO": y_prob_adaptive_lasso,
    # "RFE": y_prob_rfe,
    "Bayes": y_prob_bay
}
plot_all_roc_curves(y_test, y_probs_dict)